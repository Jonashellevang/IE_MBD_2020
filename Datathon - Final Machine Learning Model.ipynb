{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T19:51:39.856379Z",
     "start_time": "2020-03-18T19:51:39.850864Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:33:57.071441Z",
     "start_time": "2020-03-18T20:33:57.065579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score, recall_score, matthews_corrcoef, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "import pandas_profiling\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:22.835378Z",
     "start_time": "2020-03-18T20:31:20.667559Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing the data\n",
    "CSD2016 = pd.read_csv('CDS_2016_va', encoding = 'latin-1')\n",
    "CSD2017 = pd.read_csv('CDS_2017_va', encoding = 'latin-1')\n",
    "CSD2018 = pd.read_csv('CDS_2018_va', encoding = 'latin-1')\n",
    "CSD2019 = pd.read_csv('CDS_2019_NO_LABEL', encoding = 'latin-1')\n",
    "clientes = pd.read_csv(\"Clientes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:25.168096Z",
     "start_time": "2020-03-18T20:31:25.088648Z"
    }
   },
   "outputs": [],
   "source": [
    "#Renaming columns for all dataframes\n",
    "CSD2016.rename(columns={'Año Natural': 'Año_Natural', 'Tipo Material Educativo': 'Tipo_Material_Educativo', 'Grupo Editorial': 'Grupo_Editorial', 'Tipo Soporte Actual': 'Tipo_Soporte_Actual', 'Variable 1': 'Variable_1', 'Variable 2': 'Variable_2'}, inplace=True)\n",
    "CSD2019.rename(columns={'Año natural': 'Año_Natural', 'Tipo Material Educativo': 'Tipo_Material_Educativo', 'Grupo Editorial': 'Grupo_Editorial', 'Tipo Soporte Actual': 'Tipo_Soporte_Actual', 'Variable1': 'Variable_1', 'Variable2': 'Variable_2'}, inplace=True)\n",
    "CSD2017.columns = CSD2016.columns\n",
    "CSD2018.columns = CSD2016.columns\n",
    "clientes.rename(columns={'Comunidad Autónoma': 'Comunidad_Autónoma'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:27.000403Z",
     "start_time": "2020-03-18T20:31:26.433728Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cleaning variables from 2018 dataset\n",
    "CSD2018[\"Curso\"] = CSD2018[\"Curso\"].str.replace(\"c\",\"\")\n",
    "CSD2018 = CSD2018.replace({\"Año_Natural\": 18}, {\"Año_Natural\": 2018}, regex=True)\n",
    "CSD2018[\"Curso\"] = CSD2018[\"Curso\"].astype('int64')\n",
    "CSD2019[\"Variable_2\"] = CSD2019[\"Variable_2\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:42.872488Z",
     "start_time": "2020-03-18T20:31:28.637325Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a unique identifier for each record\n",
    "CSD2016[\"Unique_Id\"] = (CSD2016[\"Id_Cliente\"].astype(str) + CSD2016[\"Curso\"].astype(str) + CSD2016[\"Asignatura\"].astype(str) + CSD2016[\"Tipo_Material_Educativo\"].astype(str) + CSD2016[\"Lengua\"].astype(str) + CSD2016[\"Tipo_Soporte_Actual\"].astype(str))\n",
    "CSD2017[\"Unique_Id\"] = (CSD2017[\"Id_Cliente\"].astype(str) + CSD2017[\"Curso\"].astype(str) + CSD2017[\"Asignatura\"].astype(str) + CSD2017[\"Tipo_Material_Educativo\"].astype(str) + CSD2017[\"Lengua\"].astype(str) + CSD2017[\"Tipo_Soporte_Actual\"].astype(str))\n",
    "CSD2018[\"Unique_Id\"] = (CSD2018[\"Id_Cliente\"].astype(str) + CSD2018[\"Curso\"].astype(str) + CSD2018[\"Asignatura\"].astype(str) + CSD2018[\"Tipo_Material_Educativo\"].astype(str) + CSD2018[\"Lengua\"].astype(str) + CSD2018[\"Tipo_Soporte_Actual\"].astype(str))\n",
    "CSD2019[\"Unique_Id\"] = (CSD2019[\"Id_Cliente\"].astype(str) + CSD2019[\"Curso\"].astype(str) + CSD2019[\"Asignatura\"].astype(str) + CSD2019[\"Tipo_Material_Educativo\"].astype(str) + CSD2019[\"Lengua\"].astype(str) + CSD2019[\"Tipo_Soporte_Actual\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:46.768520Z",
     "start_time": "2020-03-18T20:31:46.350742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for 2016\n",
    "CSD2016.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:48.698910Z",
     "start_time": "2020-03-18T20:31:48.042571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for 2017\n",
    "CSD2017.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:50.040342Z",
     "start_time": "2020-03-18T20:31:49.663959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for 2018\n",
    "CSD2018.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:51.393516Z",
     "start_time": "2020-03-18T20:31:51.032524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for 2019\n",
    "CSD2019.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:31:54.265803Z",
     "start_time": "2020-03-18T20:31:52.634009Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dropping duplicates\n",
    "CSD2017.sort_values(\"Unique_Id\", inplace=True)\n",
    "CSD2017 = CSD2017.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:33:11.668610Z",
     "start_time": "2020-03-18T20:33:09.972825Z"
    }
   },
   "outputs": [],
   "source": [
    "#Changing Grupo Editiorial as string\n",
    "CSD2016[\"Grupo_Editorial\"] = CSD2016[\"Grupo_Editorial\"].astype(\"str\")\n",
    "CSD2017[\"Grupo_Editorial\"] = CSD2017[\"Grupo_Editorial\"].astype(\"str\")\n",
    "CSD2018[\"Grupo_Editorial\"] = CSD2018[\"Grupo_Editorial\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to return the number of years of the course\n",
    "def courseyears(s):\n",
    "    if (pd.isnull(s[\"Años_Curso_PY\"]) == True):\n",
    "        return 1\n",
    "    else:\n",
    "        return s[\"Años_Curso_PY\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of courses in 2016: 612727\n",
      "Number of courses in 2017: 615630\n",
      "Number of courses in 2018: 619854\n",
      "Number of courses in 2019: 617860\n"
     ]
    }
   ],
   "source": [
    "#Adding column \"Groupo_Editorial\" from the previous Year and the Number of year of the course\n",
    "CSD2016[\"Años_Curso\"] = 1\n",
    "\n",
    "CSD2016_1 = CSD2016[[\"Unique_Id\",\"Grupo_Editorial\",\"Años_Curso\"]]\n",
    "CSD2016_1.columns = [\"Unique_Id\",\"Grupo_Editorial_PY\",\"Años_Curso_PY\"]\n",
    "CSD2017 = pd.merge(CSD2017, CSD2016_1, how = \"left\", on='Unique_Id')\n",
    "CSD2017[\"Años_Curso\"] = CSD2017.apply(courseyears, axis=1)\n",
    "CSD2017 = CSD2017.drop([\"Años_Curso_PY\"], axis = 1)\n",
    "\n",
    "CSD2017_1 = CSD2017[[\"Unique_Id\",\"Grupo_Editorial\",\"Años_Curso\"]]\n",
    "CSD2017_1.columns = [\"Unique_Id\",\"Grupo_Editorial_PY\",\"Años_Curso_PY\"]\n",
    "CSD2018 = pd.merge(CSD2018, CSD2017_1,how = \"left\", on='Unique_Id')\n",
    "CSD2018[\"Años_Curso\"] = CSD2018.apply(courseyears, axis=1)\n",
    "CSD2018 = CSD2018.drop([\"Años_Curso_PY\"], axis = 1)\n",
    "\n",
    "CSD2018_1 = CSD2018[[\"Unique_Id\",\"Grupo_Editorial\",\"Años_Curso\"]]\n",
    "CSD2018_1.columns = [\"Unique_Id\",\"Grupo_Editorial_PY\",\"Años_Curso_PY\"]\n",
    "CSD2019 = pd.merge(CSD2019, CSD2018_1, how = \"left\", on='Unique_Id')\n",
    "CSD2019[\"Años_Curso\"] = CSD2019.apply(courseyears, axis=1)\n",
    "CSD2019 = CSD2019.drop([\"Años_Curso_PY\"], axis = 1)\n",
    "\n",
    "print(\"Number of courses in 2016: \" + CSD2016[\"Unique_Id\"].count().astype(str))\n",
    "print(\"Number of courses in 2017: \" + CSD2017[\"Unique_Id\"].count().astype(str))\n",
    "print(\"Number of courses in 2018: \" + CSD2018[\"Unique_Id\"].count().astype(str))\n",
    "print(\"Number of courses in 2019: \" + CSD2019[\"Unique_Id\"].count().astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:34:00.812137Z",
     "start_time": "2020-03-18T20:34:00.141846Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of courses in All Years: 1848211\n"
     ]
    }
   ],
   "source": [
    "#Concatenating the dataframes\n",
    "AllCDS = pd.concat([CSD2016, CSD2017, CSD2018], axis = 0, join = 'outer', ignore_index = False)\n",
    "print(\"Number of courses in All Years: \" + AllCDS[\"Unique_Id\"].count().astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:34:16.045898Z",
     "start_time": "2020-03-18T20:34:16.029444Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining function to return the type of change from one year to another \n",
    "def changes(df):\n",
    "    if (pd.isnull(df[\"Grupo_Editorial_PY\"]) == True) and (df[\"Grupo_Editorial\"] == \"1\") :\n",
    "        return \"New_course_SM\"\n",
    "    elif (pd.isnull(df[\"Grupo_Editorial_PY\"]) == True) and (df[\"Grupo_Editorial\"] == \"90\") :\n",
    "        return \"New_course_No-Use\"\n",
    "    elif (pd.isnull(df[\"Grupo_Editorial_PY\"]) == True) and (df[\"Grupo_Editorial\"] != \"1\") and (df[\"Grupo_Editorial\"] != \"90\"):\n",
    "        return \"New_course_Editorial\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"1\" ) and (df[\"Grupo_Editorial\"] == \"1\" ):\n",
    "        return \"SM_to_SM\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] != \"1\" ) and (df[\"Grupo_Editorial_PY\"] != \"90\" ) and (df[\"Grupo_Editorial\"] != \"1\") and (df[\"Grupo_Editorial\"] != \"90\"):\n",
    "        return \"Editorial_to_Editorial\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"90\" ) and (df[\"Grupo_Editorial\"] == \"90\"):\n",
    "        return \"No-Use_to_No-Use\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"1\" ) and (df[\"Grupo_Editorial\"] != \"1\" ) and (df[\"Grupo_Editorial\"] != \"90\" ):\n",
    "        return \"SM_to_Editorial\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] != \"1\" ) and (df[\"Grupo_Editorial\"] == \"1\" ) and (df[\"Grupo_Editorial\"] != \"90\" ):\n",
    "        return \"Editorial_to_SM\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"90\" ) and (df[\"Grupo_Editorial\"] == \"1\"):\n",
    "        return \"No-Use_to_SM\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"90\" ) and (df[\"Grupo_Editorial\"] != \"1\") and (df[\"Grupo_Editorial\"] != \"90\"):\n",
    "        return \"No-Use_to_Editorial\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"1\" ) and (df[\"Grupo_Editorial\"] == \"90\"):\n",
    "        return \"SM_to_No-Use\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] != \"1\" ) and (df[\"Grupo_Editorial_PY\"] != \"90\" ) and (df[\"Grupo_Editorial\"] == \"90\"):\n",
    "        return \"Editorial_to_No-Use\"\n",
    "    else:\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:36:32.010632Z",
     "start_time": "2020-03-18T20:34:18.687056Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a new column applying the function already created\n",
    "AllCDS[\"Change\"] = AllCDS.apply(changes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:37:07.269809Z",
     "start_time": "2020-03-18T20:37:07.102475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Editorial_to_Editorial    572905\n",
       "New_course_Editorial      478953\n",
       "No-Use_to_No-Use          291535\n",
       "New_course_No-Use         228419\n",
       "SM_to_SM                  105810\n",
       "New_course_SM             105106\n",
       "Editorial_to_No-Use        33053\n",
       "No-Use_to_Editorial        14240\n",
       "SM_to_No-Use                6926\n",
       "Editorial_to_SM             5966\n",
       "SM_to_Editorial             5298\n",
       "Name: Change, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing the changes from one year to another by type\n",
    "AllCDS[\"Change\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking all years we can observe: \n",
    "- 30% of the courses reimain using educational material from one year to another from editorials that are not SM. \n",
    "- 25% of the courses are new courses that use material from other editorials. \n",
    "- 15% of the courses have not use any material for at least two consequtive years (considering the present year).\n",
    "- 12% are **new courses that do not use any material.** \n",
    "- When **strictly looking the change \"To No Use\",** only 2.16% of the courses are in that category, **where SM represent the 0.3% of that total.**\n",
    "\n",
    "**Because of that, for the target variable we are going to define the change \"To No-Use\" including:**\n",
    "- Courses with no use of any material for two consequtive years.\n",
    "- New courses that did not decide to use any material.\n",
    "The above because capturing those courses implies to capture a business oportunity for SM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Editorial_to_Editorial    286360\n",
       "No-Use_to_No-Use          153262\n",
       "New_course_Editorial       53926\n",
       "SM_to_SM                   51327\n",
       "New_course_No-Use          29335\n",
       "Editorial_to_No-Use        15483\n",
       "New_course_SM              14225\n",
       "No-Use_to_Editorial         6626\n",
       "SM_to_No-Use                3334\n",
       "SM_to_Editorial             3061\n",
       "Editorial_to_SM             2915\n",
       "Name: Change, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllCDS[AllCDS[\"Año_Natural\"]==2018][\"Change\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:39:05.756497Z",
     "start_time": "2020-03-18T20:39:05.750606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining a function to return the name of the \"Grupo_Editorial\"\n",
    "def grupoeditorialnames(df):\n",
    "    if (pd.isnull(df[\"Grupo_Editorial_PY\"]) == True):\n",
    "        return \"New_Course\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"1\"):\n",
    "        return \"SM\"\n",
    "    elif (df[\"Grupo_Editorial_PY\"] == \"90\"):\n",
    "        return \"No-Use\"\n",
    "    else:\n",
    "        return \"Editorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:40:19.808609Z",
     "start_time": "2020-03-18T20:39:07.860351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the function to both dataframes and creating a new column with the names of the \"Grupo_Editorial\"\n",
    "AllCDS[\"Grupo_Editorial_Nombre\"] = AllCDS.apply(grupoeditorialnames, axis=1)\n",
    "CSD2019[\"Grupo_Editorial_Nombre\"] = CSD2019.apply(grupoeditorialnames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:42:02.904613Z",
     "start_time": "2020-03-18T20:42:02.730561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New_Course    812478\n",
       "Editorial     609924\n",
       "No-Use        307775\n",
       "SM            118034\n",
       "Name: Grupo_Editorial_Nombre, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllCDS[\"Grupo_Editorial_Nombre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:42:14.907170Z",
     "start_time": "2020-03-18T20:42:14.834924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Editorial     304421\n",
       "No-Use        178203\n",
       "New_Course     81022\n",
       "SM             54214\n",
       "Name: Grupo_Editorial_Nombre, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSD2019[\"Grupo_Editorial_Nombre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:42:17.772742Z",
     "start_time": "2020-03-18T20:42:17.766683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the function to return 1 or 0 in the target variable according to the type of change\n",
    "def targetvariable(df):\n",
    "    if (df[\"Change\"]) in {\"No-Use_to_No-Use\",\"SM_to_No-Use\",\"Editorial_to_No-Use\", \"New_course_No-Use\"}:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:43:03.124679Z",
     "start_time": "2020-03-18T20:42:22.037755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the function to create the target variable\n",
    "AllCDS[\"Target\"] = AllCDS.apply(targetvariable, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:43:48.326916Z",
     "start_time": "2020-03-18T20:43:48.027133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    433324\n",
       "1    182306\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the change to no-use for 2017\n",
    "AllCDS[AllCDS[\"Año_Natural\"] == 2017][\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:43:52.819213Z",
     "start_time": "2020-03-18T20:43:52.646616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    421774\n",
       "1    198080\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the change to no-use for 2018\n",
    "AllCDS[AllCDS[\"Año_Natural\"] == 2018][\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column to capture the change of previous year (Target)\n",
    "CDS2016_2 = AllCDS[AllCDS[\"Año_Natural\"]==2016]\n",
    "\n",
    "CDS2017_2 = AllCDS[AllCDS[\"Año_Natural\"]==2017]\n",
    "temp = AllCDS[AllCDS[\"Año_Natural\"]==2016][[\"Unique_Id\", \"Target\"]]\n",
    "temp.columns= [\"Unique_Id\", \"Change_PY\"]\n",
    "CDS2017_2 = pd.merge(CDS2017_2, temp, on=\"Unique_Id\", how = \"left\")\n",
    " \n",
    "CDS2018_2 = AllCDS[AllCDS[\"Año_Natural\"]==2018]\n",
    "temp = AllCDS[AllCDS[\"Año_Natural\"]==2017][[\"Unique_Id\", \"Target\"]]\n",
    "temp.columns= [\"Unique_Id\", \"Change_PY\"]\n",
    "CDS2018_2 = pd.merge(CDS2018_2, temp, on=\"Unique_Id\", how = \"left\")\n",
    "\n",
    "AllCDS = pd.concat([CDS2016_2, CDS2017_2, CDS2018_2], axis=0, join='outer', ignore_index=False)\n",
    "\n",
    "temp = AllCDS[AllCDS[\"Año_Natural\"]==2018][[\"Unique_Id\", \"Target\"]]\n",
    "temp.columns= [\"Unique_Id\", \"Change_PY\"]\n",
    "CSD2019 = pd.merge(CSD2019, temp, how = \"left\", on='Unique_Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:46:15.302030Z",
     "start_time": "2020-03-18T20:46:13.360260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging the dataframes to add information of the schools\n",
    "AllData = pd.merge(AllCDS, clientes, on=\"Id_Cliente\", how = \"left\")\n",
    "AllCSD2019 = pd.merge(CSD2019, clientes, on=\"Id_Cliente\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T20:46:43.172580Z",
     "start_time": "2020-03-18T20:46:41.221044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reordering columns\n",
    "AllData = AllData[['Unique_Id','Id_Cliente', 'Año_Natural', 'Años_Curso','Curso','Asignatura','Tipo_Material_Educativo','Lengua','Tipo_Soporte_Actual', 'Variable_1','Variable_2','Latitud','Longitud', 'Comunidad_Autónoma', 'Id_Asociación', 'Id_Subasociación', 'Titularidad', 'Grupo_Editorial','Grupo_Editorial_PY', 'Grupo_Editorial_Nombre', 'Change', 'Change_PY','Target']]\n",
    "AllCSD2019 = AllCSD2019[['Unique_Id','Id_Cliente', 'Año_Natural','Años_Curso','Curso','Asignatura','Tipo_Material_Educativo','Lengua','Tipo_Soporte_Actual', 'Variable_1','Variable_2','Latitud','Longitud', 'Comunidad_Autónoma', 'Id_Asociación', 'Id_Subasociación', 'Titularidad','Grupo_Editorial_PY', 'Grupo_Editorial_Nombre','Change_PY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_results = {}\n",
    "\n",
    "def evaluates(X_train, X_test, y_train, y_test, estimator,Report=False):\n",
    "    train_scores=[]\n",
    "    test_scores=[]\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    train_metric = cross_val_score(estimator, X_train, y_train, cv=10, scoring=\"f1\")\n",
    "    train_scores.append(np.median(train_metric))\n",
    "        \n",
    "    y_pred = estimator.predict(X_test)\n",
    "    test_score = f1_score(y_test, y_pred)\n",
    "    test_scores.append(test_score)\n",
    "        \n",
    "    if Report is True:\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T21:15:07.793392Z",
     "start_time": "2020-03-18T21:15:06.770107Z"
    }
   },
   "outputs": [],
   "source": [
    "#Making a copy of the original data\n",
    "AllTrain = copy(AllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping some columns\n",
    "AllTrain = AllTrain.drop([\"Unique_Id\", \"Change\", \"Grupo_Editorial\", \"Id_Asociación\", \"Grupo_Editorial_PY\", \"Id_Cliente\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Año_Natural                      0\n",
       "Años_Curso                       0\n",
       "Curso                            0\n",
       "Asignatura                       0\n",
       "Tipo_Material_Educativo          0\n",
       "Lengua                           0\n",
       "Tipo_Soporte_Actual              0\n",
       "Variable_1                       0\n",
       "Variable_2                       0\n",
       "Latitud                          0\n",
       "Longitud                         0\n",
       "Comunidad_Autónoma               0\n",
       "Id_Subasociación           1399275\n",
       "Titularidad                      0\n",
       "Grupo_Editorial_Nombre           0\n",
       "Change_PY                   812478\n",
       "Target                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "AllTrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values in Subasociación\n",
    "AllTrain[\"Id_Subasociación\"].fillna(\"901\", inplace = True)\n",
    "AllTrain[\"Change_PY\"].fillna(\"0\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting some columns to categorical variables\n",
    "AllTrain[\"Curso\"] = AllTrain[\"Curso\"].astype(str)\n",
    "AllTrain[\"Asignatura\"] = AllTrain[\"Asignatura\"].astype(str)\n",
    "AllTrain[\"Tipo_Material_Educativo\"] = AllTrain[\"Tipo_Material_Educativo\"].astype(str)\n",
    "AllTrain[\"Lengua\"] = AllTrain[\"Lengua\"].astype(str)\n",
    "AllTrain[\"Tipo_Soporte_Actual\"] = AllTrain[\"Tipo_Soporte_Actual\"].astype(str)\n",
    "AllTrain[\"Id_Subasociación\"] = AllTrain[\"Id_Subasociación\"].astype(str)\n",
    "AllTrain[\"Change_PY\"] = AllTrain[\"Change_PY\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping data of the first year\n",
    "AllTrain = AllTrain.drop(AllTrain[AllTrain[\"Año_Natural\"] == 2016].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binnary encoding\n",
    "encodeCol = AllTrain.columns[AllTrain.dtypes==object].tolist()\n",
    "Binary = ce.BinaryEncoder(cols=encodeCol)\n",
    "AllTrainTemp = Binary.fit_transform(AllTrain[encodeCol])\n",
    "AllTrain = pd.concat([AllTrain,AllTrainTemp], axis=1)\n",
    "AllTrain = AllTrain.drop(encodeCol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T21:18:03.925268Z",
     "start_time": "2020-03-18T21:17:52.095129Z"
    }
   },
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "splits = np.array([0.8, 0.2])\n",
    "\n",
    "#Shuffle your input\n",
    "AllTrain = AllTrain.sample(frac=1)\n",
    "\n",
    "#Split into 2 parts\n",
    "AllTrainTrain, AllTrainTest = np.array_split(\n",
    "    AllTrain, (splits[:-1].cumsum() * len(AllTrain)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T21:17:25.799Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating features and target variables for the train\n",
    "x_train = AllTrainTrain.loc[:, AllTrainTrain.columns != 'Target']\n",
    "y_train = AllTrainTrain['Target']\n",
    "\n",
    "#Creating features and target variables for the test\n",
    "x_test = AllTrainTest.loc[:, AllTrainTest.columns != 'Target']\n",
    "y_test = AllTrainTest['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T21:17:30.911Z"
    }
   },
   "outputs": [],
   "source": [
    "#Transforming to dataframe\n",
    "x_train = pd.DataFrame(x_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95    170769\n",
      "           1       0.92      0.85      0.88     76328\n",
      "\n",
      "    accuracy                           0.93    247097\n",
      "   macro avg       0.93      0.91      0.92    247097\n",
      "weighted avg       0.93      0.93      0.93    247097\n",
      "\n",
      "[[164808   5961]\n",
      " [ 11325  65003]]\n"
     ]
    }
   ],
   "source": [
    "#Defining the model\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth=15) \n",
    "\n",
    "#Evaluating the model\n",
    "tree_train, tree_test =evaluates(x_train, x_test, y_train, y_test, tree, Report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Change_PY_2</td>\n",
       "      <td>0.825527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Años_Curso</td>\n",
       "      <td>0.041882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tipo_Material_Educativo_2</td>\n",
       "      <td>0.023035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Longitud</td>\n",
       "      <td>0.012727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latitud</td>\n",
       "      <td>0.012237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable_2</td>\n",
       "      <td>0.012109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Grupo_Editorial_Nombre_2</td>\n",
       "      <td>0.010425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Asignatura_2</td>\n",
       "      <td>0.007384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Asignatura_5</td>\n",
       "      <td>0.006456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Asignatura_6</td>\n",
       "      <td>0.005280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Asignatura_7</td>\n",
       "      <td>0.005009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tipo_Material_Educativo_1</td>\n",
       "      <td>0.004870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Curso_2</td>\n",
       "      <td>0.004029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variable_1</td>\n",
       "      <td>0.003798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Curso_3</td>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable  importance\n",
       "48                Change_PY_2    0.825527\n",
       "1                  Años_Curso    0.041882\n",
       "22  Tipo_Material_Educativo_2    0.023035\n",
       "5                    Longitud    0.012727\n",
       "4                     Latitud    0.012237\n",
       "3                  Variable_2    0.012109\n",
       "45   Grupo_Editorial_Nombre_2    0.010425\n",
       "14               Asignatura_2    0.007384\n",
       "17               Asignatura_5    0.006456\n",
       "18               Asignatura_6    0.005280\n",
       "19               Asignatura_7    0.005009\n",
       "21  Tipo_Material_Educativo_1    0.004870\n",
       "8                     Curso_2    0.004029\n",
       "2                  Variable_1    0.003798\n",
       "9                     Curso_3    0.003570"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best features so we can build on top of that\n",
    "pd.concat((pd.DataFrame(x_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(tree.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the baseline\n",
    "def baselinedataset(data):\n",
    "    data = copy(AllData)\n",
    "    data = data.drop([\"Unique_Id\", \"Change\", \"Grupo_Editorial\", \"Id_Asociación\", \"Grupo_Editorial_PY\", \"Id_Cliente\"], axis = 1)\n",
    "    data[\"Id_Subasociación\"].fillna(\"901\", inplace = True)\n",
    "    data[\"Change_PY\"].fillna(\"0\", inplace = True)\n",
    "    data[\"Curso\"] = data[\"Curso\"].astype(str)\n",
    "    data[\"Asignatura\"] = data[\"Asignatura\"].astype(str)\n",
    "    data[\"Tipo_Material_Educativo\"] = data[\"Tipo_Material_Educativo\"].astype(str)\n",
    "    data[\"Lengua\"] = data[\"Lengua\"].astype(str)\n",
    "    data[\"Tipo_Soporte_Actual\"] = data[\"Tipo_Soporte_Actual\"].astype(str)\n",
    "    data[\"Id_Subasociación\"] = data[\"Id_Subasociación\"].astype(str)\n",
    "    data[\"Change_PY\"] = data[\"Change_PY\"].astype(str)\n",
    "    data = data.drop(data[data[\"Año_Natural\"] == 2016].index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a copy of the original data\n",
    "AllTrain = copy(AllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the previous transformations\n",
    "AllTrain = baselinedataset(AllTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Latitude and Longitude as categorical so they are not detected as outliers\n",
    "AllTrain[\"Latitud\"] = AllTrain[\"Latitud\"].astype(str)\n",
    "AllTrain[\"Longitud\"] = AllTrain[\"Longitud\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asignatura                     0\n",
       "Año_Natural                    0\n",
       "Años_Curso                     0\n",
       "Change_PY                      0\n",
       "Comunidad_Autónoma             0\n",
       "Curso                          0\n",
       "Grupo_Editorial_Nombre         0\n",
       "Id_Subasociación               0\n",
       "Latitud                        0\n",
       "Lengua                         0\n",
       "Longitud                       0\n",
       "Target                         0\n",
       "Tipo_Material_Educativo        0\n",
       "Tipo_Soporte_Actual            0\n",
       "Titularidad                    0\n",
       "Variable_1                 64966\n",
       "Variable_2                 60995\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Detecting outliers\n",
    "Q1 = AllTrain.quantile(0.25)\n",
    "Q3 = AllTrain.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "((AllTrain < (Q1 - 1.5 * IQR)) |(AllTrain > (Q3 + 1.5 * IQR))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers\n",
    "AllTrain = AllTrain[~((AllTrain < (Q1 - 1.5 * IQR)) |(AllTrain > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Laitude and Longitud as float again\n",
    "AllTrain[\"Latitud\"] = AllTrain[\"Latitud\"].astype(float)\n",
    "AllTrain[\"Longitud\"] = AllTrain[\"Longitud\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binnary encoding\n",
    "encodeCol = AllTrain.columns[AllTrain.dtypes==object].tolist()\n",
    "Binary = ce.BinaryEncoder(cols=encodeCol)\n",
    "AllTrainTemp = Binary.fit_transform(AllTrain[encodeCol])\n",
    "AllTrain = pd.concat([AllTrain,AllTrainTemp], axis=1)\n",
    "AllTrain = AllTrain.drop(encodeCol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "splits = np.array([0.8, 0.2])\n",
    "\n",
    "#Shuffle your input\n",
    "AllTrain = AllTrain.sample(frac=1)\n",
    "\n",
    "#Split into 2 parts\n",
    "AllTrainTrain, AllTrainTest = np.array_split(\n",
    "    AllTrain, (splits[:-1].cumsum() * len(AllTrain)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features and target variables for the train\n",
    "x_train = AllTrainTrain.loc[:, AllTrainTrain.columns != 'Target']\n",
    "y_train = AllTrainTrain['Target']\n",
    "\n",
    "#Creating features and target variables for the test\n",
    "x_test = AllTrainTest.loc[:, AllTrainTest.columns != 'Target']\n",
    "y_test = AllTrainTest['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming to dataframe\n",
    "x_train = pd.DataFrame(x_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95    156992\n",
      "           1       0.92      0.86      0.89     72832\n",
      "\n",
      "    accuracy                           0.93    229824\n",
      "   macro avg       0.93      0.91      0.92    229824\n",
      "weighted avg       0.93      0.93      0.93    229824\n",
      "\n",
      "[[151219   5773]\n",
      " [ 10369  62463]]\n"
     ]
    }
   ],
   "source": [
    "#Defining the model\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth=15) \n",
    "\n",
    "#Evaluating the model\n",
    "tree_train, tree_test =evaluates(x_train, x_test, y_train, y_test, tree, Report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Change_PY_2</td>\n",
       "      <td>0.819346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Años_Curso</td>\n",
       "      <td>0.043671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tipo_Material_Educativo_2</td>\n",
       "      <td>0.023320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Longitud</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latitud</td>\n",
       "      <td>0.012774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable_2</td>\n",
       "      <td>0.010782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Grupo_Editorial_Nombre_2</td>\n",
       "      <td>0.010651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Asignatura_7</td>\n",
       "      <td>0.007132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Asignatura_5</td>\n",
       "      <td>0.006487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asignatura_3</td>\n",
       "      <td>0.006469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tipo_Material_Educativo_1</td>\n",
       "      <td>0.004896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Asignatura_6</td>\n",
       "      <td>0.004610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variable_1</td>\n",
       "      <td>0.004353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Asignatura_2</td>\n",
       "      <td>0.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Curso_2</td>\n",
       "      <td>0.003733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable  importance\n",
       "48                Change_PY_2    0.819346\n",
       "1                  Años_Curso    0.043671\n",
       "22  Tipo_Material_Educativo_2    0.023320\n",
       "5                    Longitud    0.013707\n",
       "4                     Latitud    0.012774\n",
       "3                  Variable_2    0.010782\n",
       "45   Grupo_Editorial_Nombre_2    0.010651\n",
       "19               Asignatura_7    0.007132\n",
       "17               Asignatura_5    0.006487\n",
       "15               Asignatura_3    0.006469\n",
       "21  Tipo_Material_Educativo_1    0.004896\n",
       "18               Asignatura_6    0.004610\n",
       "2                  Variable_1    0.004353\n",
       "14               Asignatura_2    0.003876\n",
       "8                     Curso_2    0.003733"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best features so we can build on top of that\n",
    "pd.concat((pd.DataFrame(x_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(tree.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the baseline\n",
    "def outliersdataset(data):\n",
    "    data = copy(AllData)\n",
    "    data = data.drop([\"Unique_Id\", \"Change\", \"Grupo_Editorial\", \"Id_Asociación\", \"Grupo_Editorial_PY\", \"Id_Cliente\"], axis = 1)\n",
    "    data[\"Id_Subasociación\"].fillna(\"901\", inplace = True)\n",
    "    data[\"Change_PY\"].fillna(\"0\", inplace = True)\n",
    "    data[\"Curso\"] = data[\"Curso\"].astype(str)\n",
    "    data[\"Asignatura\"] = data[\"Asignatura\"].astype(str)\n",
    "    data[\"Tipo_Material_Educativo\"] = data[\"Tipo_Material_Educativo\"].astype(str)\n",
    "    data[\"Lengua\"] = data[\"Lengua\"].astype(str)\n",
    "    data[\"Tipo_Soporte_Actual\"] = data[\"Tipo_Soporte_Actual\"].astype(str)\n",
    "    data[\"Id_Subasociación\"] = data[\"Id_Subasociación\"].astype(str)\n",
    "    data[\"Change_PY\"] = data[\"Change_PY\"].astype(str)\n",
    "    data = data.drop(data[data[\"Año_Natural\"] == 2016].index)\n",
    "    data[\"Latitud\"] = data[\"Latitud\"].astype(str)\n",
    "    data[\"Longitud\"] = data[\"Longitud\"].astype(str)\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    data = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    data[\"Latitud\"] = data[\"Latitud\"].astype(float)\n",
    "    data[\"Longitud\"] = data[\"Longitud\"].astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a copy of the original data\n",
    "AllTrain = copy(AllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the previous transformations\n",
    "AllTrain = outliersdataset(AllTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to return categories of the courses\n",
    "def gruposcurso(df):    \n",
    "    if np.isin(df[\"Curso\"], [\"20\", \"21\", \"22\", \"23\", \"24\",\"25\"]):\n",
    "            return \"Infantil\"\n",
    "    elif np.isin(df[\"Curso\"], [\"26\", \"27\", \"28\", \"29\", \"30\", \"31\"]):\n",
    "            return \"Primaria\"\n",
    "    elif np.isin(df[\"Curso\"], [\"32\", \"33\", \"34\", \"35\"]):\n",
    "            return \"Secundaria\"\n",
    "    elif np.isin(df[\"Curso\"], [\"36\", \"37\"]):\n",
    "            return \"Bachillerato\"\n",
    "    else:\n",
    "         return \"Misc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column with the groups of Curso\n",
    "AllTrain[\"Grupo_Curso\"] = AllTrain.apply(gruposcurso, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column Variable 3 using Variable 1 and 2 to get the value of each \n",
    "AllTrain[\"Variable_3\"] = AllTrain['Variable_2'] / AllTrain['Variable_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Año_Natural                   0\n",
       "Años_Curso                    0\n",
       "Curso                         0\n",
       "Asignatura                    0\n",
       "Tipo_Material_Educativo       0\n",
       "Lengua                        0\n",
       "Tipo_Soporte_Actual           0\n",
       "Variable_1                    0\n",
       "Variable_2                    0\n",
       "Latitud                       0\n",
       "Longitud                      0\n",
       "Comunidad_Autónoma            0\n",
       "Id_Subasociación              0\n",
       "Titularidad                   0\n",
       "Grupo_Editorial_Nombre        0\n",
       "Change_PY                     0\n",
       "Target                        0\n",
       "Grupo_Curso                   0\n",
       "Variable_3                 3372\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for nulls in the new variable\n",
    "AllTrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing outliers for 0\n",
    "AllTrain[\"Variable_3\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binnary encoding\n",
    "encodeCol = AllTrain.columns[AllTrain.dtypes==object].tolist()\n",
    "Binary = ce.BinaryEncoder(cols=encodeCol)\n",
    "AllTrainTemp = Binary.fit_transform(AllTrain[encodeCol])\n",
    "AllTrain = pd.concat([AllTrain,AllTrainTemp], axis=1)\n",
    "AllTrain = AllTrain.drop(encodeCol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "splits = np.array([0.8, 0.2])\n",
    "\n",
    "#Shuffle your input\n",
    "AllTrain = AllTrain.sample(frac=1)\n",
    "\n",
    "#Split into 2 parts\n",
    "AllTrainTrain, AllTrainTest = np.array_split(\n",
    "    AllTrain, (splits[:-1].cumsum() * len(AllTrain)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features and target variables for the train\n",
    "x_train = AllTrainTrain.loc[:, AllTrainTrain.columns != 'Target']\n",
    "y_train = AllTrainTrain['Target']\n",
    "\n",
    "#Creating features and target variables for the test\n",
    "x_test = AllTrainTest.loc[:, AllTrainTest.columns != 'Target']\n",
    "y_test = AllTrainTest['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95    156364\n",
      "           1       0.92      0.86      0.89     73460\n",
      "\n",
      "    accuracy                           0.93    229824\n",
      "   macro avg       0.93      0.91      0.92    229824\n",
      "weighted avg       0.93      0.93      0.93    229824\n",
      "\n",
      "[[151205   5159]\n",
      " [ 10629  62831]]\n"
     ]
    }
   ],
   "source": [
    "#Defining the model\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth=15) \n",
    "\n",
    "#Evaluating the model\n",
    "tree_train, tree_test =evaluates(x_train, x_test, y_train, y_test, tree, Report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Change_PY_2</td>\n",
       "      <td>0.815985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Años_Curso</td>\n",
       "      <td>0.042878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tipo_Material_Educativo_2</td>\n",
       "      <td>0.022936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Variable_3</td>\n",
       "      <td>0.017269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latitud</td>\n",
       "      <td>0.014024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Longitud</td>\n",
       "      <td>0.012097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asignatura_2</td>\n",
       "      <td>0.011321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Grupo_Editorial_Nombre_2</td>\n",
       "      <td>0.010534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable_2</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tipo_Soporte_Actual_0</td>\n",
       "      <td>0.005053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tipo_Material_Educativo_1</td>\n",
       "      <td>0.004808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Grupo_Curso_1</td>\n",
       "      <td>0.003691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Asignatura_7</td>\n",
       "      <td>0.003436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Asignatura_6</td>\n",
       "      <td>0.003164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variable_1</td>\n",
       "      <td>0.003123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable  importance\n",
       "49                Change_PY_2    0.815985\n",
       "1                  Años_Curso    0.042878\n",
       "23  Tipo_Material_Educativo_2    0.022936\n",
       "6                  Variable_3    0.017269\n",
       "4                     Latitud    0.014024\n",
       "5                    Longitud    0.012097\n",
       "15               Asignatura_2    0.011321\n",
       "46   Grupo_Editorial_Nombre_2    0.010534\n",
       "3                  Variable_2    0.005989\n",
       "27      Tipo_Soporte_Actual_0    0.005053\n",
       "22  Tipo_Material_Educativo_1    0.004808\n",
       "51              Grupo_Curso_1    0.003691\n",
       "20               Asignatura_7    0.003436\n",
       "19               Asignatura_6    0.003164\n",
       "2                  Variable_1    0.003123"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best features so we can build on top of that\n",
    "pd.concat((pd.DataFrame(x_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(tree.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Optimizing the depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal F1: 0.8901, for max_depth=19\n"
     ]
    }
   ],
   "source": [
    "min_depth = 1\n",
    "max_depth = 30\n",
    "parameters = {'max_depth':range(min_depth, max_depth)}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), scoring='f1', \n",
    "                         param_grid=parameters)\n",
    "grid_tree.fit(x_train, y_train)\n",
    "best_tree = grid_tree.best_estimator_\n",
    "\n",
    "\n",
    "print('Optimal F1: {:.4f}, for max_depth={}'.format(\n",
    "    grid_tree.best_score_, grid_tree.best_params_['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95    156364\n",
      "           1       0.92      0.86      0.89     73460\n",
      "\n",
      "    accuracy                           0.93    229824\n",
      "   macro avg       0.93      0.91      0.92    229824\n",
      "weighted avg       0.93      0.93      0.93    229824\n",
      "\n",
      "[[151129   5235]\n",
      " [ 10085  63375]]\n"
     ]
    }
   ],
   "source": [
    "#Defining the model with the optimal depth\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth=19) \n",
    "\n",
    "#Evaluating the model\n",
    "tree_train, tree_test =evaluates(x_train, x_test, y_train, y_test, tree, Report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Change_PY_2</td>\n",
       "      <td>0.763550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Años_Curso</td>\n",
       "      <td>0.040806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latitud</td>\n",
       "      <td>0.030451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Longitud</td>\n",
       "      <td>0.027437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tipo_Material_Educativo_2</td>\n",
       "      <td>0.021462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Variable_3</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable_2</td>\n",
       "      <td>0.013657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asignatura_2</td>\n",
       "      <td>0.010756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Grupo_Editorial_Nombre_2</td>\n",
       "      <td>0.009858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variable_1</td>\n",
       "      <td>0.008140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tipo_Soporte_Actual_1</td>\n",
       "      <td>0.004828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tipo_Material_Educativo_1</td>\n",
       "      <td>0.004499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Asignatura_7</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Asignatura_6</td>\n",
       "      <td>0.003447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Asignatura_3</td>\n",
       "      <td>0.003285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable  importance\n",
       "49                Change_PY_2    0.763550\n",
       "1                  Años_Curso    0.040806\n",
       "4                     Latitud    0.030451\n",
       "5                    Longitud    0.027437\n",
       "23  Tipo_Material_Educativo_2    0.021462\n",
       "6                  Variable_3    0.020400\n",
       "3                  Variable_2    0.013657\n",
       "15               Asignatura_2    0.010756\n",
       "46   Grupo_Editorial_Nombre_2    0.009858\n",
       "2                  Variable_1    0.008140\n",
       "28      Tipo_Soporte_Actual_1    0.004828\n",
       "22  Tipo_Material_Educativo_1    0.004499\n",
       "20               Asignatura_7    0.004098\n",
       "19               Asignatura_6    0.003447\n",
       "16               Asignatura_3    0.003285"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best features so we can build on top of that\n",
    "pd.concat((pd.DataFrame(x_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(tree.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When optimizing the depth of the tree the model does not improves, therefore we decide to try a different algorithm to see if we can capture more changes to no-use in the courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Randome Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the final transformations\n",
    "def featuredataset(data):\n",
    "    data = copy(AllData)\n",
    "    data = data.drop([\"Unique_Id\", \"Change\", \"Grupo_Editorial\", \"Id_Asociación\", \"Grupo_Editorial_PY\", \"Id_Cliente\"], axis = 1)\n",
    "    data[\"Id_Subasociación\"].fillna(\"901\", inplace = True)\n",
    "    data[\"Change_PY\"].fillna(\"0\", inplace = True)\n",
    "    data[\"Curso\"] = data[\"Curso\"].astype(str)\n",
    "    data[\"Asignatura\"] = data[\"Asignatura\"].astype(str)\n",
    "    data[\"Tipo_Material_Educativo\"] = data[\"Tipo_Material_Educativo\"].astype(str)\n",
    "    data[\"Lengua\"] = data[\"Lengua\"].astype(str)\n",
    "    data[\"Tipo_Soporte_Actual\"] = data[\"Tipo_Soporte_Actual\"].astype(str)\n",
    "    data[\"Id_Subasociación\"] = data[\"Id_Subasociación\"].astype(str)\n",
    "    data[\"Change_PY\"] = data[\"Change_PY\"].astype(str)\n",
    "    data = data.drop(data[data[\"Año_Natural\"] == 2016].index)\n",
    "    data[\"Latitud\"] = data[\"Latitud\"].astype(str)\n",
    "    data[\"Longitud\"] = data[\"Longitud\"].astype(str)\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    data = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    data[\"Latitud\"] = data[\"Latitud\"].astype(float)\n",
    "    data[\"Longitud\"] = data[\"Longitud\"].astype(float)\n",
    "    data[\"Grupo_Curso\"] = data.apply(gruposcurso, axis=1)\n",
    "    data[\"Variable_3\"] = data['Variable_2'] / data['Variable_1']\n",
    "    data[\"Variable_3\"].fillna(0, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a copy of the original data\n",
    "AllTrain = copy(AllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the previous transformations\n",
    "AllTrain = featuredataset(AllTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binnary encoding\n",
    "encodeCol = AllTrain.columns[AllTrain.dtypes==object].tolist()\n",
    "Binary = ce.BinaryEncoder(cols=encodeCol)\n",
    "AllTrainTemp = Binary.fit_transform(AllTrain[encodeCol])\n",
    "AllTrain = pd.concat([AllTrain,AllTrainTemp], axis=1)\n",
    "AllTrain = AllTrain.drop(encodeCol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "splits = np.array([0.8, 0.2])\n",
    "\n",
    "#Shuffle your input\n",
    "AllTrain = AllTrain.sample(frac=1)\n",
    "\n",
    "#Split into 2 parts\n",
    "AllTrainTrain, AllTrainTest = np.array_split(\n",
    "    AllTrain, (splits[:-1].cumsum() * len(AllTrain)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features and target variables for the train\n",
    "x_train = AllTrainTrain.loc[:, AllTrainTrain.columns != 'Target']\n",
    "y_train = AllTrainTrain['Target']\n",
    "\n",
    "#Creating features and target variables for the test\n",
    "x_test = AllTrainTest.loc[:, AllTrainTest.columns != 'Target']\n",
    "y_test = AllTrainTest['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96    156825\n",
      "           1       0.93      0.88      0.90     72999\n",
      "\n",
      "    accuracy                           0.94    229824\n",
      "   macro avg       0.93      0.92      0.93    229824\n",
      "weighted avg       0.94      0.94      0.94    229824\n",
      "\n",
      "[[151665   5160]\n",
      " [  9103  63896]]\n"
     ]
    }
   ],
   "source": [
    "#Defining the model again but this time using Random Forest\n",
    "rf = RandomForestClassifier(criterion= 'gini',\n",
    "                                n_estimators=500, \n",
    "                                max_features='auto',\n",
    "                                oob_score = True, \n",
    "                                random_state=1,\n",
    "                                n_jobs = -1)\n",
    "\n",
    "#Using the evaluate function to evaluate the model over our data\n",
    "rf_train, rf_test = evaluates(x_train, x_test, y_train, y_test, rf, Report = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a copy of the original data\n",
    "AllTrain = copy(AllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the previous transformations\n",
    "AllTrain = featuredataset(AllTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binnary encoding\n",
    "encodeCol = AllTrain.columns[AllTrain.dtypes==object].tolist()\n",
    "Binary = ce.BinaryEncoder(cols=encodeCol)\n",
    "AllTrainTemp = Binary.fit_transform(AllTrain[encodeCol])\n",
    "AllTrain = pd.concat([AllTrain,AllTrainTemp], axis=1)\n",
    "AllTrain = AllTrain.drop(encodeCol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "splits = np.array([0.8, 0.2])\n",
    "\n",
    "#Shuffle your input\n",
    "AllTrain = AllTrain.sample(frac=1)\n",
    "\n",
    "#Split into 2 parts\n",
    "AllTrainTrain, AllTrainTest = np.array_split(\n",
    "    AllTrain, (splits[:-1].cumsum() * len(AllTrain)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features and target variables for the train\n",
    "x_train = AllTrainTrain.loc[:, AllTrainTrain.columns != 'Target']\n",
    "y_train = AllTrainTrain['Target']\n",
    "\n",
    "#Creating features and target variables for the test\n",
    "x_test = AllTrainTest.loc[:, AllTrainTest.columns != 'Target']\n",
    "y_test = AllTrainTest['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96    156411\n",
      "           1       0.94      0.90      0.92     73413\n",
      "\n",
      "    accuracy                           0.95    229824\n",
      "   macro avg       0.95      0.94      0.94    229824\n",
      "weighted avg       0.95      0.95      0.95    229824\n",
      "\n",
      "[[152095   4316]\n",
      " [  7515  65898]]\n"
     ]
    }
   ],
   "source": [
    "#Defining the model again but this time using XGBoost\n",
    "xgb = xgb.XGBClassifier(learning_rate=0.1,n_estimators=100,\n",
    "                                random_state=0,\n",
    "                                  max_depth=20,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "xgb_train, xgb_test = evaluates(x_train, x_test, y_train, y_test, xgb, Report = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the results from this model, we decide that this is the final model we are going to use to predict.\n",
    "\n",
    "The model has a F1 score of 92%. \n",
    "- 94% of precision that means that for the courses I predicted to be No-Use (1), my model fail to correctly predict 6% of the cases.\n",
    "- 92% of recall that basically indicates that my model fails to capture 8% of the courses that actually become No-Use. \n",
    "\n",
    "This model was trained considering the following transformations on the data:\n",
    "- Handling N/As\n",
    "- Dropping outliers\n",
    "- Feature Engineering to reduce dimensionality (Groups of Educational Levels for the courses)\n",
    "- Feature Creation to capture changes to No-Use of previous years and to understand the diferent kind of changes of the educational material year to year\n",
    "- Binnary Encoding to reduce dimensionality in variables with high cardinality.\n",
    "\n",
    "Probably there is still so much room to improve the model going deep in the feature engineering.\n",
    "\n",
    "The model probably can be improve with the use of location variables. Also with more feature creation making use of the different information regarding the school, etc.\n",
    "\n",
    "Finally, considering that we are dealing with a pretty unbalanced data, undersampling could also be use to capture the strict change to no use in the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the final transformations for our training \n",
    "def finaltranformationtrain():\n",
    "    data = copy(AllData)\n",
    "    data = data.drop([\"Unique_Id\", \"Change\", \"Grupo_Editorial\", \"Id_Asociación\", \"Grupo_Editorial_PY\", \"Id_Cliente\"], axis = 1)\n",
    "    data[\"Id_Subasociación\"].fillna(\"901\", inplace = True)\n",
    "    data[\"Change_PY\"].fillna(\"0\", inplace = True)\n",
    "    data[\"Curso\"] = data[\"Curso\"].astype(str)\n",
    "    data[\"Asignatura\"] = data[\"Asignatura\"].astype(str)\n",
    "    data[\"Tipo_Material_Educativo\"] = data[\"Tipo_Material_Educativo\"].astype(str)\n",
    "    data[\"Lengua\"] = data[\"Lengua\"].astype(str)\n",
    "    data[\"Tipo_Soporte_Actual\"] = data[\"Tipo_Soporte_Actual\"].astype(str)\n",
    "    data[\"Id_Subasociación\"] = data[\"Id_Subasociación\"].astype(str)\n",
    "    data[\"Change_PY\"] = data[\"Change_PY\"].astype(str)\n",
    "    data = data.drop(data[data[\"Año_Natural\"] == 2016].index)\n",
    "    data[\"Latitud\"] = data[\"Latitud\"].astype(str)\n",
    "    data[\"Longitud\"] = data[\"Longitud\"].astype(str)\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    data = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    data[\"Latitud\"] = data[\"Latitud\"].astype(float)\n",
    "    data[\"Longitud\"] = data[\"Longitud\"].astype(float)\n",
    "    data[\"Grupo_Curso\"] = data.apply(gruposcurso, axis=1)\n",
    "    data[\"Variable_3\"] = data['Variable_2'] / data['Variable_1']\n",
    "    data[\"Variable_3\"].fillna(0, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the final transformations for our test \n",
    "def finaltransformationtest():\n",
    "    data = copy(AllCSD2019)\n",
    "    data = data.drop([\"Unique_Id\", \"Id_Asociación\", \"Grupo_Editorial_PY\", \"Id_Cliente\"], axis = 1)\n",
    "    data[\"Id_Subasociación\"].fillna(\"901\", inplace = True)\n",
    "    data[\"Change_PY\"].fillna(\"0\", inplace = True)\n",
    "    data[\"Curso\"] = data[\"Curso\"].astype(str)\n",
    "    data[\"Asignatura\"] = data[\"Asignatura\"].astype(str)\n",
    "    data[\"Tipo_Material_Educativo\"] = data[\"Tipo_Material_Educativo\"].astype(str)\n",
    "    data[\"Lengua\"] = data[\"Lengua\"].astype(str)\n",
    "    data[\"Tipo_Soporte_Actual\"] = data[\"Tipo_Soporte_Actual\"].astype(str)\n",
    "    data[\"Id_Subasociación\"] = data[\"Id_Subasociación\"].astype(str)\n",
    "    data[\"Change_PY\"] = data[\"Change_PY\"].astype(str)\n",
    "    data = data.drop(data[data[\"Año_Natural\"] == 2016].index)\n",
    "    data[\"Grupo_Curso\"] = data.apply(gruposcurso, axis=1)\n",
    "    data[\"Variable_3\"] = data['Variable_2'] / data['Variable_1']\n",
    "    data[\"Variable_3\"].fillna(0, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming both train and test\n",
    "TransformedTrain = finaltranformationtrain()\n",
    "TransformedTest = finaltransformationtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating my target variables from the features\n",
    "TransformedTrainFeatures = TransformedTrain.drop([\"Target\"], axis = 1)\n",
    "TransformedTrainTarget = TransformedTrain[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining both dataframes to make the binnary encoding\n",
    "FinalCSD = pd.concat([TransformedTrainFeatures, TransformedTest], axis=0, join='outer', ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binnary encoding\n",
    "encodeCol = FinalCSD.columns[FinalCSD.dtypes==object].tolist()\n",
    "Binary = ce.BinaryEncoder(cols=encodeCol)\n",
    "FinalCSDTemp = Binary.fit_transform(FinalCSD[encodeCol])\n",
    "FinalCSD = pd.concat([FinalCSD,FinalCSDTemp], axis=1)\n",
    "FinalCSD = FinalCSD.drop(encodeCol, axis=1)\n",
    "\n",
    "TBETrainFeatures = FinalCSD[FinalCSD[\"Año_Natural\"] != 2019]\n",
    "TBETest = FinalCSD[FinalCSD[\"Año_Natural\"] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting\n",
    "\n",
    "#Training the model with all the data\n",
    "xgb.fit(TBETrainFeatures, TransformedTrainTarget)\n",
    "\n",
    "#Predicting\n",
    "y_pred = xgb.predict(TBETest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSD2019[\"Target\"] = y_pred\n",
    "CSD2019.to_csv('CDS_2019_va.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
